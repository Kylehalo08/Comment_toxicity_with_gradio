{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "718146b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: tensorflow-gpu in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.4.3)\n",
      "Requirement already satisfied: sklearn in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (21.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.43.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (0.23.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow tensorflow-gpu pandas matplotlib sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "650c6eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "113cba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(os.path.join('comment_toxicity','train.csv','train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c7bcc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43bdc020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94f5a2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c914a92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
       "       'insult', 'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ec28b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['comment_text']\n",
    "y=df[df.columns[2:]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b48432a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         Explanation\\nWhy the edits made under my usern...\n",
      "1         D'aww! He matches this background colour I'm s...\n",
      "2         Hey man, I'm really not trying to edit war. It...\n",
      "3         \"\\nMore\\nI can't make any real suggestions on ...\n",
      "4         You, sir, are my hero. Any chance you remember...\n",
      "                                ...                        \n",
      "159566    \":::::And for the second time of asking, when ...\n",
      "159567    You should be ashamed of yourself \\n\\nThat is ...\n",
      "159568    Spitzer \\n\\nUmm, theres no actual article for ...\n",
      "159569    And it looks like it was actually you who put ...\n",
      "159570    \"\\nAnd ... I really don't think you understand...\n",
      "Name: comment_text, Length: 159571, dtype: object\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " ...\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbde9504",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES=200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c23432f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TextVectorization(max_tokens=MAX_FEATURES,output_sequence_length=1800,output_mode='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "889bc0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.adapt(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0cc3d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_text=vectorizer(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "746b51ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(159571, 1800), dtype=int64, numpy=\n",
       "array([[  643,    76,     2, ...,     0,     0,     0],\n",
       "       [    1,    54,  2506, ...,     0,     0,     0],\n",
       "       [  425,   440,    70, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [32141,  7329,   383, ...,     0,     0,     0],\n",
       "       [    5,    12,   533, ...,     0,     0,     0],\n",
       "       [    5,     8,   130, ...,     0,     0,     0]], dtype=int64)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0d11eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=tf.data.Dataset.from_tensor_slices((vectorized_text,y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e1c33e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=(TensorSpec(shape=(1800,), dtype=tf.int64, name=None), TensorSpec(shape=(6,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ca29c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=dataset.cache()\n",
    "dataset=dataset.shuffle(160000)\n",
    "dataset=dataset.batch(16)\n",
    "dataset=dataset.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b433b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X,batch_y=dataset.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6faf3682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 1800)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0708c9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5422c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=dataset.take(int(len(dataset)*.7))\n",
    "val=dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\n",
    "test=dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b652a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator=train.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec1fd609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   51,  1149,    35, ...,     0,     0,     0],\n",
       "        [15747,  2281,   223, ...,     0,     0,     0],\n",
       "        [    5,    14,     9, ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [    8,  3025,    12, ...,     0,     0,     0],\n",
       "        [    2,  5470,    11, ...,     0,     0,     0],\n",
       "        [   46,    33,    15, ...,     0,     0,     0]], dtype=int64),\n",
       " array([[0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 1, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 1, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0]], dtype=int64))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fabdb80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a8223a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating Sequential Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dropout,Bidirectional,Dense,Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fe9f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Embedding(MAX_FEATURES+1,32))\n",
    "model.add(Bidirectional(LSTM(32,activation='tanh')))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(6,activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2d0f34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='CategoricalCrossentropy',optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38b0b48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          6400032   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 64)               16640     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,491,686\n",
      "Trainable params: 6,491,686\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0deee06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "6981/6981 [==============================] - 5086s 728ms/step - loss: 684419.3750 - val_loss: 901135.5625\n",
      "Epoch 2/3\n",
      "6981/6981 [==============================] - 5805s 832ms/step - loss: 5610167.5000 - val_loss: 9929309.0000\n",
      "Epoch 3/3\n",
      "6981/6981 [==============================] - 5205s 745ms/step - loss: 12385833.0000 - val_loss: 21275404.0000\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train,epochs=3,validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd0cd8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [684419.375, 5610167.5, 12385833.0],\n",
       " 'val_loss': [901135.5625, 9929309.0, 21275404.0]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6016efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9dda8a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 225ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text=vectorizer('You freaking suck!')\n",
    "batch_X,batch_Y=test.as_numpy_iterator().next()\n",
    "batch_X\n",
    "batch_Y\n",
    "res=model.predict(np.expand_dims(input_text,0))\n",
    "model.predict(batch_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba10861e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))': /packages/4b/02/8bcd66c2a44714b3c3d076ff3bf49b3a247338a47f31adb00567841e15a0/aiohttp-3.8.1-cp39-cp39-win_amd64.whl"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-3.0.24-py3-none-any.whl (5.1 MB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.11.3)\n",
      "Collecting httpx\n",
      "  Downloading httpx-0.23.0-py3-none-any.whl (84 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (2021.10.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (3.4.3)\n",
      "Collecting markdown-it-py[linkify,plugins]\n",
      "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (1.20.3)\n",
      "Collecting python-multipart\n",
      "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
      "Requirement already satisfied: paramiko in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (2.7.2)\n",
      "Collecting pydantic\n",
      "  Downloading pydantic-1.9.1-cp39-cp39-win_amd64.whl (2.0 MB)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (1.3.4)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (2.26.0)\n",
      "Collecting fastapi\n",
      "  Downloading fastapi-0.78.0-py3-none-any.whl (54 kB)\n",
      "Collecting uvicorn\n",
      "  Downloading uvicorn-0.18.2-py3-none-any.whl (57 kB)\n",
      "Collecting orjson\n",
      "  Downloading orjson-3.7.6-cp39-none-win_amd64.whl (188 kB)\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting analytics-python\n",
      "  Downloading analytics_python-1.4.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (8.4.0)\n",
      "Collecting pycryptodome\n",
      "  Downloading pycryptodome-3.15.0-cp35-abi3-win_amd64.whl (1.9 MB)\n",
      "Collecting ffmpy\n",
      "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp39-cp39-win_amd64.whl (554 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jinja2) (1.1.1)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp39-cp39-win_amd64.whl (28 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from aiohttp->gradio) (2.0.4)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp39-cp39-win_amd64.whl (122 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.0-cp39-cp39-win_amd64.whl (33 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from aiohttp->gradio) (21.2.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp->gradio) (3.2)\n",
      "Collecting backoff==1.10.0\n",
      "  Downloading backoff-1.10.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting monotonic>=1.5\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from analytics-python->gradio) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from analytics-python->gradio) (2.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->gradio) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->gradio) (1.26.7)\n",
      "Collecting starlette==0.19.1\n",
      "  Downloading starlette-0.19.1-py3-none-any.whl (63 kB)\n",
      "Collecting anyio<5,>=3.4.0\n",
      "  Downloading anyio-3.6.1-py3-none-any.whl (80 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from starlette==0.19.1->fastapi->gradio) (3.10.0.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from anyio<5,>=3.4.0->starlette==0.19.1->fastapi->gradio) (1.2.0)\n",
      "Collecting rfc3986[idna2008]<2,>=1.3\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting httpcore<0.16.0,>=0.15.0\n",
      "  Downloading httpcore-0.15.0-py3-none-any.whl (68 kB)\n",
      "Collecting h11<0.13,>=0.11\n",
      "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.1-py3-none-any.whl (10 kB)\n",
      "Collecting mdit-py-plugins\n",
      "  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl (43 kB)\n",
      "Collecting linkify-it-py~=1.0\n",
      "  Downloading linkify_it_py-1.0.3-py3-none-any.whl (19 kB)\n",
      "Collecting uc-micro-py\n",
      "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->gradio) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->gradio) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->gradio) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas->gradio) (2021.3)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from paramiko->gradio) (1.4.0)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from paramiko->gradio) (3.2.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from paramiko->gradio) (3.4.8)\n",
      "Requirement already satisfied: cffi>=1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from bcrypt>=3.1.3->paramiko->gradio) (1.14.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko->gradio) (2.20)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from uvicorn->gradio) (8.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click>=7.0->uvicorn->gradio) (0.4.4)\n",
      "Building wheels for collected packages: ffmpy, python-multipart\n",
      "  Building wheel for ffmpy (setup.py): started\n",
      "  Building wheel for ffmpy (setup.py): finished with status 'done'\n",
      "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4710 sha256=f6e27156192e6860cfcd0a3608d0811fd76af22a8ffd8bb4f69456cdcf600aa8\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\91\\e2\\96\\f676aa08bfd789328c6576cd0f1fde4a3d686703bb0c247697\n",
      "  Building wheel for python-multipart (setup.py): started\n",
      "  Building wheel for python-multipart (setup.py): finished with status 'done'\n",
      "  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31678 sha256=8a087148b58a6f320e1c789f29f8565af8ef85ef217bb4782c587d2766c8fc5e\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\fe\\04\\d1\\a10661cc45f03c3cecda50deb2d2c22f57b4e84a75b2a5987e\n",
      "Successfully built ffmpy python-multipart\n",
      "Installing collected packages: mdurl, uc-micro-py, rfc3986, multidict, markdown-it-py, h11, frozenlist, anyio, yarl, starlette, pydantic, monotonic, mdit-py-plugins, linkify-it-py, httpcore, backoff, async-timeout, aiosignal, uvicorn, python-multipart, pydub, pycryptodome, orjson, httpx, ffmpy, fastapi, analytics-python, aiohttp, gradio\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 2.2.0\n",
      "    Uninstalling anyio-2.2.0:\n",
      "      Successfully uninstalled anyio-2.2.0\n",
      "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 analytics-python-1.4.0 anyio-3.6.1 async-timeout-4.0.2 backoff-1.10.0 fastapi-0.78.0 ffmpy-0.3.0 frozenlist-1.3.0 gradio-3.0.24 h11-0.12.0 httpcore-0.15.0 httpx-0.23.0 linkify-it-py-1.0.3 markdown-it-py-2.1.0 mdit-py-plugins-0.3.0 mdurl-0.1.1 monotonic-1.6 multidict-6.0.2 orjson-3.7.6 pycryptodome-3.15.0 pydantic-1.9.1 pydub-0.25.1 python-multipart-0.0.5 rfc3986-1.5.0 starlette-0.19.1 uc-micro-py-1.0.1 uvicorn-0.18.2 yarl-1.7.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cf45c12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0108a2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('toxicity.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3cc186b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def score_comment(comment):\n",
    "    vectorized_comment=vectorizer([comment])\n",
    "    result=model.predict(vectorized_comment)\n",
    "    res=tf.argmax(result,0)\n",
    "    text=''\n",
    "    if res==0:\n",
    "        text='This comment is toxic'\n",
    "    elif res==1:\n",
    "        text='This comment is severely toxic'\n",
    "    elif res==2:\n",
    "        text='This comment is obscene'\n",
    "    elif res==3:\n",
    "        text='This comment is threat'\n",
    "    elif res==4:\n",
    "        text='This comment is insult'\n",
    "    elif res==5:\n",
    "        text='This comment is an identity threat'\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6bea3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
      "  warnings.warn(value)\n"
     ]
    }
   ],
   "source": [
    "interface =gr.Interface(fn=score_comment,inputs=gr.inputs.Textbox(lines=2,placeholder='Comment to score'),outputs='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "98948754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861/\n",
      "Running on public URL: https://51884.gradio.app\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://51884.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x14e5c26b640>,\n",
       " 'http://127.0.0.1:7861/',\n",
       " 'https://51884.gradio.app')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 154ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\gradio\\routes.py\", line 255, in run_predict\n",
      "    output = await app.blocks.process_api(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\gradio\\blocks.py\", line 548, in process_api\n",
      "    predictions, duration = await self.call_function(fn_index, processed_input)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\gradio\\blocks.py\", line 463, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\anyio\\to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\gradio\\interface.py\", line 514, in <lambda>\n",
      "    lambda *args: self.run_prediction(args)[0]\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\gradio\\interface.py\", line 718, in run_prediction\n",
      "    prediction = predict_fn(*processed_input)\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_13304/1241760811.py\", line 7, in score_comment\n",
      "    if res==0:\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1070, in __bool__\n",
      "    return bool(self._numpy())\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"
     ]
    }
   ],
   "source": [
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c425e0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
